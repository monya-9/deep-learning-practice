{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMf3/7XIQ74gD2UAGXJNxEM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/monya-9/deep-learning-practice/blob/main/02_cnn_cifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN â€“ CIFAR-10 ë¶„ë¥˜ê¸°\n",
        "\n",
        "CIFAR-10 ë°ì´í„°ì…‹(32Ã—32 ì»¬ëŸ¬ ì´ë¯¸ì§€, 10 í´ë˜ìŠ¤)ì„ CNNìœ¼ë¡œ ë¶„ë¥˜í•˜ëŠ” ì‹¤ìŠµì…ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "URp_7RqEWLJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "2Ns4C4O3WMfw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. ë°ì´í„°ì…‹ ë¡œë“œ & ì „ì²˜ë¦¬\n",
        "# CIFAR-10: 32x32 ì»¬ëŸ¬ ì´ë¯¸ì§€, í´ë˜ìŠ¤ 10ê°œ\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # ì´ë¯¸ì§€ë¥¼ Tensorë¡œ ë³€í™˜\n",
        "    transforms.Normalize((0.5, 0.5, 0.5),  # RGB ì±„ë„ í‰ê· \n",
        "                         (0.5, 0.5, 0.5))  # RGB ì±„ë„ í‘œì¤€í¸ì°¨\n",
        "])\n",
        "\n",
        "# í•™ìŠµ ë°ì´í„°\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                         download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "# í…ŒìŠ¤íŠ¸ ë°ì´í„°\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                        download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
        "\n",
        "# í´ë˜ìŠ¤ ì´ë¦„\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_Ken3eKWoKK",
        "outputId": "f57d096b-305a-48fa-c4e7-443e37f1000d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 170M/170M [00:04<00:00, 41.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Normalizeë¡œ í•™ìŠµ ì•ˆì •í™”ë¥¼ ìœ„í•œ ì •ê·œí™”\n",
        "2. batch_size = 64 ì„¤ì •"
      ],
      "metadata": {
        "id": "tuHHogmwaBnb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. CNN ëª¨ë¸ ì •ì˜\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1) # 32x32 â†’ 32x32\n",
        "        self.pool = nn.MaxPool2d(2, 2)              # 32x32 â†’ 16x16\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)# 16x16 â†’ 16x16\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 256)\n",
        "        self.fc2 = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 8 * 8)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "net = SimpleCNN().to(device)"
      ],
      "metadata": {
        "id": "MtJLgtx-W4ap"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. viewë¡œ feature mapì„ fc ë ˆì´ì–´ ì…ë ¥ í˜•íƒœë¡œ ë³€í™˜\n",
        "2. ReLU ë¹ˆì„ í˜• í™œì„±í™” í•¨ìˆ˜ ì‚¬ìš©"
      ],
      "metadata": {
        "id": "w-9fSUdRaQjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. ì†ì‹¤í•¨ìˆ˜ & ì˜µí‹°ë§ˆì´ì €\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "x20mGi5XXA1s"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. CrossEntropyLoss ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ì— ì í•©í•œ ì†ì‹¤ í•¨ìˆ˜\n",
        "2. Adam optimizer ì‘ê³  ì•ˆì •ì ì¸ í•™ìŠµë¥ ì„ ìœ„í•´ ì„ íƒ"
      ],
      "metadata": {
        "id": "_pImTQXoaYUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. í•™ìŠµ\n",
        "for epoch in range(5):  # 5 epoch\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "    print(f\"[Epoch {epoch+1}] loss: {running_loss/len(trainloader):.3f}\")\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJtR-n2EXB1m",
        "outputId": "87719c56-320f-4f42-a430-cf507994d009"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1] loss: 1.323\n",
            "[Epoch 2] loss: 0.936\n",
            "[Epoch 3] loss: 0.768\n",
            "[Epoch 4] loss: 0.636\n",
            "[Epoch 5] loss: 0.522\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. í•™ìŠµ ì§„í–‰ ìƒí™©ì„ Epoch ë‹¨ìœ„ë¡œ ë¡œê·¸ ì¶œë ¥"
      ],
      "metadata": {
        "id": "cb5yPeaoarur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. ì •í™•ë„ í…ŒìŠ¤íŠ¸\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Accuracy on test images: {100 * correct / total:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lI1EKQDXDNv",
        "outputId": "d0596478-ea9f-40c3-c73e-dc218e3e33b6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test images: 72.15%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. torch.no_grad()ë¡œ í‰ê°€ ì‹œ ë¶ˆí•„ìš”í•œ gradient ê³„ì‚°ì„ ë°©ì§€\n",
        "2. ìµœì¢… í…ŒìŠ¤íŠ¸ ì •í™•ë„ë¥¼ %ë¡œ ì¶œë ¥"
      ],
      "metadata": {
        "id": "P9d027ItavCz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ”¹ ì •í™•ë„ë¥¼ 80% ì´ìƒìœ¼ë¡œ ë†’ì´ëŠ” ë°©ë²•\n",
        "- CNN ì¸µ ì¶”ê°€: Conv ë ˆì´ì–´ë¥¼ ë” ìŒ“ê±°ë‚˜ ì±„ë„ ìˆ˜ ëŠ˜ë¦¬ê¸°\n",
        "- ë°ì´í„° ì¦ê°•(Data Augmentation): RandomCrop, RandomHorizontalFlip ë“±\n",
        "- Dropout ì ìš©: FC ì¸µ ì „ì— Dropout ì¶”ê°€ â†’ ê³¼ì í•© ë°©ì§€\n",
        "- í•™ìŠµ Epoch ëŠ˜ë¦¬ê¸° / í•™ìŠµë¥  ì¡°ì •"
      ],
      "metadata": {
        "id": "j-JytKZQbJF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =======================\n",
        "# 1) ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "# =======================\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# =======================\n",
        "# 2) ë°ì´í„°ì…‹ ë¡œë“œ & ì „ì²˜ë¦¬\n",
        "# =======================\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),  # â¬† ì¶”ê°€: ë°ì´í„° ì¦ê°•\n",
        "    transforms.RandomCrop(32, padding=4),  # â¬† ì¶”ê°€: ë°ì´í„° ì¦ê°•\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True,\n",
        "                                       transform=transforms.Compose([\n",
        "                                           transforms.ToTensor(),\n",
        "                                           transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        "                                       ]))\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# =======================\n",
        "# 3) CNN ëª¨ë¸ ì •ì˜\n",
        "# =======================\n",
        "class ImprovedCNN(nn.Module):  # â¬† ë³€ê²½: ëª¨ë¸ ì´ë¦„ & êµ¬ì¡°\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3,32,3,padding=1)\n",
        "        self.conv2 = nn.Conv2d(32,64,3,padding=1)\n",
        "        self.conv3 = nn.Conv2d(64,128,3,padding=1)  # â¬† ì¶”ê°€: Conv3\n",
        "        self.pool = nn.MaxPool2d(2,2)\n",
        "        self.dropout = nn.Dropout(0.3)             # â¬† ì¶”ê°€: Dropout\n",
        "        self.fc1 = nn.Linear(128*4*4,256)          # â¬† ë³€ê²½: FC ì…ë ¥ í¬ê¸°\n",
        "        self.fc2 = nn.Linear(256,10)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = self.pool(torch.relu(self.conv3(x)))  # â¬† ì¶”ê°€: Conv3\n",
        "        x = x.view(-1,128*4*4)\n",
        "        x = self.dropout(torch.relu(self.fc1(x)))  # â¬† ì¶”ê°€: Dropout\n",
        "        return self.fc2(x)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "net = ImprovedCNN().to(device)\n",
        "\n",
        "# =======================\n",
        "# 4) ì†ì‹¤í•¨ìˆ˜ & ì˜µí‹°ë§ˆì´ì €\n",
        "# =======================\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "# =======================\n",
        "# 5) í•™ìŠµ\n",
        "# =======================\n",
        "for epoch in range(20):  # â¬† ë³€ê²½: Epoch 20ìœ¼ë¡œ ì¦ê°€\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f\"[Epoch {epoch+1}] loss: {running_loss/len(trainloader):.3f}\")\n",
        "\n",
        "print(\"Finished Training\")\n",
        "\n",
        "# =======================\n",
        "# 6) í…ŒìŠ¤íŠ¸ ì •í™•ë„\n",
        "# =======================\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Accuracy on test images: {100 * correct / total:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWoYhIQQbk5G",
        "outputId": "bdc01f0c-07ec-411b-e932-3428c155d1e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1] loss: 1.615\n",
            "[Epoch 2] loss: 1.272\n",
            "[Epoch 3] loss: 1.097\n",
            "[Epoch 4] loss: 0.988\n",
            "[Epoch 5] loss: 0.905\n",
            "[Epoch 6] loss: 0.850\n",
            "[Epoch 7] loss: 0.809\n"
          ]
        }
      ]
    }
  ]
}